{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d5bdce9-6c55-4a6b-83e2-c46fc28d70e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import pyarrow.dataset as ds\n",
    "import gcsfs\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "import h5py\n",
    "import anndata as ad\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e82306-9095-4509-8e6a-34efa50cf87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab38efe-2a58-40e5-9e7a-5bccb71cea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize GCS file system for reading data from GCS\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "gcs_base_path = \"gs://arc-ctc-tahoe100/2025-02-25/\" # GCS bucket path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa43c0d8-3c7c-40f5-b52b-cdae720bf9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = \"/\".join([gcs_base_path.rstrip(\"/\"), 'metadata', 'sample_metadata.parquet'])\n",
    "sample_metadata = ds.dataset(infile, filesystem=fs, format=\"parquet\").head(1500).to_pandas()\n",
    "sample_metadata[sample_metadata['drug'] == 'Afatinib']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda452a-c33a-4918-8bba-33e1fa9b660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to list files \n",
    "def get_file_table(gcs_base_path: str, target: str=None, endswith: str=None):\n",
    "    files = fs.glob(\"/\".join([gcs_base_path.rstrip(\"/\"), \"**\"]))\n",
    "    if target:\n",
    "        files = [f for f in files if os.path.basename(f) == target]\n",
    "    elif endswith:\n",
    "        files = [f for f in files if f.endswith(endswith)]\n",
    "    file_list = []\n",
    "    for f in files:\n",
    "        file_list.append(f.split(\"/\")[-2:-1] + [f])\n",
    "    return pd.DataFrame(file_list, columns=[\"parent\", \"final_address\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f704d171-ad95-4d57-bbbf-e128d8d708f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "List_of_files = get_file_table(gcs_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e06d2-ddc6-4ea0-ac84-a0c454eda0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "for i in range(3, 15):\n",
    "    filename = f\"plate{i}_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad\"\n",
    "    source = f\"gs://arc-ctc-tahoe100/2025-02-25/h5ad/{filename}\"\n",
    "    destination = f\"Data/{filename}\"\n",
    "    subprocess.run([\"gsutil\", \"cp\", source, destination], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41be81c-7907-4c31-b0db-f1df08523823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import scipy.sparse as sp\n",
    "\n",
    "for i in tqdm(range(4, 15)):\n",
    "    plate =f\"plate{i}\"\n",
    "    filename = f\"Data/{plate}_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad\"\n",
    "    print(f\"Starting: {filename}\")\n",
    "    file_start_time = time.time()\n",
    "    adata = sc.read_h5ad(filename, backed = \"r\")\n",
    "    adata.obs['pseduobulk_group'] = adata.obs['cell_name'].astype(str) + \"_\" + adata.obs['drugname_drugconc'].astype(str)\n",
    "    unique_groups = adata.obs['pseduobulk_group'].unique()\n",
    "    # Initialize a zero-matrix to accumulate pseudobulk counts\n",
    "    pseudobulk_matrix = np.zeros((len(unique_groups), adata.shape[1]), dtype=np.float32)\n",
    "    BATCH_SIZE = 600000\n",
    "    start_time = time.time()\n",
    "    # Process in chunks\n",
    "    for i in range(0, adata.n_obs, BATCH_SIZE):\n",
    "        batch_start_time = time.time()\n",
    "        batch = adata[i : i + BATCH_SIZE, :]  # Load chunk from disk\n",
    "        batch_X = batch.X  # Keep sparse\n",
    "        \n",
    "        # Get sample IDs for this batch\n",
    "        batch_groups = batch.obs['pseduobulk_group']\n",
    "    \n",
    "        # Aggregate gene counts per sample\n",
    "        for j, group in enumerate(unique_groups):\n",
    "            mask = batch_groups == group\n",
    "            if np.any(mask):\n",
    "                group_data = batch_X[mask, :]  # Sparse matrix of the group\n",
    "                pseudobulk_matrix[j, :] += group_data.sum(axis=0).A1  # Convert to dense array for summing\n",
    "    \n",
    "        # End timer for the current batch\n",
    "        batch_end_time = time.time()\n",
    "        batch_time = batch_end_time - batch_start_time\n",
    "        print(f\"Processed batch {i // BATCH_SIZE + 1}/{(adata.n_obs // BATCH_SIZE)+1} in {batch_time:.2f} seconds\")\n",
    "    \n",
    "    # Save the aggregated pseudobulk matrix into the backed H5AD file\n",
    "    pseudobulk_adata = ad.AnnData(\n",
    "        X=pseudobulk_matrix,  # Gene expression matrix\n",
    "        obs=pd.DataFrame({'pseudobulk_group': unique_groups}),  # Sample metadata (index = sample names)\n",
    "        var=adata.var,  # Gene metadata (index = gene names)\n",
    "    )\n",
    "    \n",
    "    # Save in backed mode\n",
    "    pseudobulk_adata.write(f'Data/{plate}.h5ad', compression='gzip')\n",
    "    file_end_time = time.time()\n",
    "    file_time = file_end_time - file_start_time\n",
    "    print(f\"Saved: {filename} in {file_time:.2f} seconds\")\n",
    "print(\"Pseudobulk analysis saved successfully in backed mode!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7bba4d-8e73-4060-838a-65e6d2bb7c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adata_list = []\n",
    "file_list = [f\"plate{i}.h5ad\" for i in range(1, 15)]\n",
    "for file in file_list:\n",
    "    file_path = os.path.join(\"Data\", file)\n",
    "    print(f\"Loading {file_path} ...\")\n",
    "    \n",
    "    adata = sc.read_h5ad(file_path, backed = 'r')  # Read in backed mode to avoid excessive RAM usage\n",
    "    adata_list.append(adata)\n",
    "\n",
    "# Concatenate all AnnData objects while appending cells\n",
    "adata_combined = adata_list[0].concatenate(*adata_list[1:], join=\"inner\")\n",
    "print(f\"Shape after concatenation: {adata_combined.shape}\")\n",
    "\n",
    "# Adding metadata to the anndata \n",
    "\n",
    "adata_combined.obs.index = adata_combined.obs['pseudobulk_group'].astype(str) + adata_combined.obs['batch'].astype(str)\n",
    "adata_combined.obs['batch'] = 'plate_' + (adata_combined.obs['batch'].astype(int) + 1).astype(str)\n",
    "adata_combined.obs['cell_name'] =  adata_combined.obs['pseudobulk_group'].str.extract(r\"^(.*?)_\\[\")\n",
    "adata_combined.obs['drug_name'] =  adata_combined.obs['pseudobulk_group'].str.extract(r\"\\[\\('([^']+)',\")\n",
    "adata_combined.obs['concentration, uM'] =  adata_combined.obs['pseudobulk_group'].str.extract(r\"\\(\\s*'[^']+',\\s*([\\d\\.]+),\")\n",
    "\n",
    "# Add lineage to the obs dataframe: \n",
    "cell_info = pd.read_csv(\"Data/cell_line.csv\")\n",
    "cell_to_lineage = dict(zip(cell_info[\"Cell_line\"], cell_info[\"lineage\"]))\n",
    "adata_combined.obs[\"lineage\"] = adata_combined.obs[\"cell_name\"].map(cell_to_lineage)\n",
    "\n",
    "print(\"Added metadata to the Anndata object\")\n",
    "\n",
    "adata_combined.write(f'Data/all_plates.h5ad', compression='gzip')\n",
    "\n",
    "print(\"Saved concatenated file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d74bbb-8f50-4a77-91f5-3728d1f2f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad('/home/pranayagarwal/Documents/tahoe_100M/Data/all_plates.h5ad', backed = \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67378825-1871-4305-af83-0188efdf785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.to_csv(\"/home/pranayagarwal/Documents/tahoe_100M/Data/meta_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33e6b77-851b-4a18-b664-2abbe3b4c89e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
